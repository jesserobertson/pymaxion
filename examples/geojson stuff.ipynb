{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "## Mapping with Folium\n",
      "\n",
      "The first thing is to make sure you have access to the relevant libraries. The default Anaconda distro comes with most of what you'll need but you also need some geospatial ones.\n",
      "\n",
      "Uncomment and run these commands to install the relevant binaries into your current environment (works for Python 3, on linux machines). They add my binstar channel to your conda install, and then install the prebuilt binaries that I provide. You can also install from pip if you have that available."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# !conda config --add channels jesserobertson\n",
      "# !conda install folium shapely descartes geojson fiona"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "## Data munging\n",
      "\n",
      "The first thing is to get our data into a useable form for the years that Peter has already analyzed. We're going to stick this into a pandas Dataframe for later use, since Leaflet has nice data binding functions to map a dataframe into a chloropleth map.\n",
      "\n",
      "First we need to know where our data is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas, os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_location = ('../EGU Text Mining/sed-based_Analysis_Postdam/codebase_grepster/'\n",
      "                + 'output/latest_results/results_from_grepster016/FOSS_query')\n",
      "# os.listdir(data_location)  # Uncomment to check you've got the right place"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "The cound data is in files keyed by year, so we need to slurp this into a nice table to play with it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_template = 'g16_{year}_osgeo20140604_foss20140603_countries.csv'\n",
      "analyzed_years = list(range(2009, 2015))  # Note that last year is not included in range\n",
      "\n",
      "# Accumnulate results from results file\n",
      "results = {}\n",
      "for year in analyzed_years:\n",
      "    filename = os.path.join(data_location,\n",
      "                            filename_template.format(year=year))\n",
      "    with open(filename) as fhandle:\n",
      "        results[year] = {}\n",
      "        for line in fhandle:\n",
      "            # Each line contains a country,count \n",
      "            country, count = line.split(',')\n",
      "            if country == 'Russian Federation':  # We need to fix this for later\n",
      "                results[year]['Russia'] = int(count)\n",
      "            elif country != '':\n",
      "                results[year][country] = int(count)\n",
      "\n",
      "# Convert results to Pandas dataframe for easier munging\n",
      "table = pandas.DataFrame(results).sort()\n",
      "table.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "For each year we only need a few of the total country boundaries, and the others will all have NaNs. We can pull these out of the table using the dropna method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "year = 2013\n",
      "print(table[year].dropna().index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "## Getting country shapes\n",
      "\n",
      "Ok, so folium lets us use GeoJSON data and pandas data binding to [generate choropleth maps](http://folium.readthedocs.org/en/latest/#binding-data). We can pull the data from [Natural Earth](http://www.naturalearthdata.com/), who provide this information as ESRI shapefiles. We'd rather have this stuff as GeoJSON so next we need to use [fiona](https://pypi.python.org/pypi/Fiona/) to generate the relevant geojson subsets from our shapefile (which has _everything_ in it). This saves us from getting our hands dirty with `ogr2ogr` and gdal. \n",
      "\n",
      "We can download this data from Natural Earth straight away (assuming you have wget)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# !wget http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip\n",
      "# !wget http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/physical/ne_10m_coastline.zip\n",
      "!unzip -of ne_10m_admin_0_map_subunits.zip\n",
      "!unzip -of ne_10m_coastline.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "But we don't want everything in the file, just the countries that we care about. Fortunately Natural Earth provide country names/ISO codes etc as metadata in the shapefile. To find out what to query we can look at the metadata schema given in the shapefile:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fiona\n",
      "\n",
      "with fiona.drivers():\n",
      "    with fiona.open('ne_10m_admin_0_map_subunits.shp', 'r') as source:\n",
      "        data = pandas.DataFrame((s['properties'] for s in source))\n",
      "\n",
      "data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['ADMIN'].unique()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "So we can match on the key \"ADMIN\" in the \"properties\" of each shape in the shapefile, and can now get the geometry of the countries we care about. There are also multiple bits of each country in the dataset (e.g. Sardinia/the Scillies and Italy are all seperate), so we need to merge their polygons."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fiona\n",
      "from collections import defaultdict\n",
      "from shapely.geometry import asShape\n",
      "from shapely.ops import cascaded_union\n",
      "\n",
      "countries = defaultdict(list)\n",
      "with fiona.drivers():\n",
      "    with fiona.open('ne_10m_admin_0_map_subunits.shp', 'r') as source:\n",
      "        for s in source:\n",
      "            ident = s['properties']['ADMIN']\n",
      "            countries[ident].append(asShape(s['geometry']))\n",
      "\n",
      "# Union up all the shapes for a given country, and stash back to geoJSON format\n",
      "for country, shapes in countries.items():\n",
      "    countries[country] = cascaded_union(shapes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countries['Italy']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with fiona.drivers():\n",
      "    with fiona.open('ne_10m_coastline.shp', 'r') as source:\n",
      "        coastline = cascaded_union(\n",
      "            [asShape(s['geometry']) for s in source\n",
      "             if s['properties']['scalerank'] < 5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "And now we can play with them!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countries['Italy']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countries['Australia']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import descartes, shapely\n",
      "\n",
      "def add_patches(shapes, axes=None, **format_keywords):\n",
      "    \"\"\" Add some patches given some formatting arguments\n",
      "    \n",
      "        If axes are not specified, just adds these to the current axis\n",
      "    \"\"\"\n",
      "    # See where we're at already\n",
      "    if axes is None:\n",
      "        axes = plt.gca()\n",
      "    lowx, highx = axes.get_xlim()\n",
      "    lowy, highy = axes.get_ylim()\n",
      "    \n",
      "    # Add new shapes\n",
      "    if type(shapes) is shapely.geometry.Polygon:\n",
      "        shapes = [shapes]\n",
      "    for shape in shapes:\n",
      "        axes.add_patch(descartes.PolygonPatch(shape, **format_keywords))\n",
      "        bounds = shape.bounds\n",
      "        lowx, highx = min(lowx, bounds[0]), max(highx, bounds[2])\n",
      "        lowy, highy = min(lowy, bounds[1]), max(highy, bounds[3])\n",
      "    \n",
      "    # Update axes limits\n",
      "    axes.set_axis_off()\n",
      "    axes.set_aspect('equal')\n",
      "    axes.set_xlim(lowx, highx)\n",
      "    axes.set_ylim(lowy, highy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for country, count in scale(data).items():\n",
      "    print(country, count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "year = 2013\n",
      "data = table[year].dropna()\n",
      "dmin, dmax = data.min(), data.max()\n",
      "scale = lambda d: (d - dmin) / (dmax - dmin)\n",
      "\n",
      "fig = plt.figure(figsize=(41, 41))\n",
      "colormap = plt.get_cmap('coolwarm')\n",
      "for country, scale in scale(data).items():\n",
      "    add_patches(countries[country], \n",
      "                linewidth=2, facecolor=colormap(scale), \n",
      "                edgecolor='black', alpha=0.6)\n",
      "    \n",
      "# Add coastline\n",
      "axes = fig.gca()\n",
      "for line in coastline:\n",
      "    axes.plot(*line.xy, color='gray', linewidth=1, zorder=1)\n",
      "fig.savefig('map.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "We can regroup the selected shapes back into a geoJSON FeatureCollection to make it easier to use with folium"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import geojson\n",
      "\n",
      "with fiona.drivers():\n",
      "    with fiona.open('ne_10m_admin_0_map_subunits.shp', 'r') as source:\n",
      "        for year in analyzed_years:\n",
      "            # Work out which countries we want\n",
      "            countries_with_data = set(table[year].dropna().index)\n",
      "            \n",
      "            # Construct a FeatureCollection of these countries\n",
      "            features = []\n",
      "            for country in set(table[year].dropna().index):\n",
      "                feature = geojson.Feature(geometry=countries[country],\n",
      "                                          id=country,\n",
      "                                          properties={'name': country})\n",
      "                features.append(feature)\n",
      "            \n",
      "            # Dump these out to file\n",
      "            sinkfile = 'countries_{0}.geojson'.format(year)\n",
      "            with open(sinkfile, 'w') as sink:\n",
      "                geojson.dump(geojson.FeatureCollection(features), sink)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "So we now have the relevant shapes to play with for the year we care about"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "## Generating choropleth maps in leaflet\n",
      "\n",
      "So now we have all the puzzle pieces in place"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import folium\n",
      "from IPython.display import HTML\n",
      "\n",
      "def display(m, height=1000):\n",
      "    \"\"\"Takes a folium instance and embed HTML.\"\"\"\n",
      "    m._build_map()\n",
      "    srcdoc = m.HTML.replace('\"', '&quot;')\n",
      "    embed = HTML('<iframe srcdoc=\"{0}\" '\n",
      "                 'style=\"width: 100%; height: {1}px; '\n",
      "                 'border: none\"></iframe>'.format(srcdoc, height))\n",
      "    return embed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "year = 2013"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "We also have to pull our index out into a table column to get the data binding to work properly and convert the table keys to string values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataframe = table.reset_index(level=0)\n",
      "dataframe['country'] = dataframe['index']\n",
      "del dataframe['index']\n",
      "for year in analyzed_years:\n",
      "    dataframe[str(year)] = dataframe[year]\n",
      "    del dataframe[year]\n",
      "dataframe.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "outputs": [],
     "source": [
      "Now we can generate the map, and bind the data for a given year in our table to it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[{c: count for c, count in zip(df['country'], df['count'])}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the counts that we want\n",
      "df = dataframe[['country', str(year)]].dropna()\n",
      "df['count'] = df[str(year)]\n",
      "del df[str(year)]\n",
      "print(df.head())\n",
      "# with open('data.json', 'w') as fhandle:\n",
      "#     fhandle.write(str({c: count for c, count in zip(df['country'], df['count'])}))\n",
      "\n",
      "del map2\n",
      "map2 = folium.Map(location=[48, 20],\n",
      "                  zoom_start=2,\n",
      "                  width=750, height=450,\n",
      "                  tiles='Mapbox Bright')\n",
      "# map2.geo_json(geo_path='countries_2013.json'.format(year),\n",
      "#               fill_color='YlGn', fill_opacity=0.7, line_opacity=0.2)\n",
      "in_current = lambda f: os.path.join(os.path.abspath(os.getcwd()), f)\n",
      "map2.geo_json(data=df, data_out='counts.json', geo_path='countries.json', \n",
      "              columns=['country', 'count'], key_on='feature.id', \n",
      "              fill_color='YlOrRd', fill_opacity=0.7, line_opacity=0.2)\n",
      "map2.create_map(path='index.html')\n",
      "# inline_map(map2, height=450)"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countries"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import descartes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from shapely.ops import cascaded_union\n",
      "\n",
      "world_outline = cascaded_union(countries.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "add_patches(world_outline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}